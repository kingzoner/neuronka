{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:70: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      " - 144s - loss: 1.7620 - acc: 0.3514 - val_loss: 1.3379 - val_acc: 0.5056\n",
      "Epoch 2/25\n",
      " - 137s - loss: 1.3367 - acc: 0.5176 - val_loss: 1.1791 - val_acc: 0.5856\n",
      "Epoch 3/25\n",
      " - 128s - loss: 1.1752 - acc: 0.5807 - val_loss: 1.1456 - val_acc: 0.5998\n",
      "Epoch 4/25\n",
      " - 119s - loss: 1.0670 - acc: 0.6239 - val_loss: 0.9190 - val_acc: 0.6784\n",
      "Epoch 5/25\n",
      " - 108s - loss: 0.9807 - acc: 0.6548 - val_loss: 0.8706 - val_acc: 0.6936\n",
      "Epoch 6/25\n",
      " - 104s - loss: 0.9105 - acc: 0.6794 - val_loss: 0.7988 - val_acc: 0.7242\n",
      "Epoch 7/25\n",
      " - 104s - loss: 0.8675 - acc: 0.6965 - val_loss: 0.7899 - val_acc: 0.7246\n",
      "Epoch 8/25\n",
      " - 104s - loss: 0.8264 - acc: 0.7096 - val_loss: 0.7430 - val_acc: 0.7388\n",
      "Epoch 9/25\n",
      " - 104s - loss: 0.7974 - acc: 0.7208 - val_loss: 0.8050 - val_acc: 0.7164\n",
      "Epoch 10/25\n",
      " - 106s - loss: 0.7671 - acc: 0.7326 - val_loss: 0.7222 - val_acc: 0.7584\n",
      "Epoch 11/25\n",
      " - 104s - loss: 0.7494 - acc: 0.7396 - val_loss: 0.7137 - val_acc: 0.7554\n",
      "Epoch 12/25\n",
      " - 103s - loss: 0.7243 - acc: 0.7473 - val_loss: 0.9178 - val_acc: 0.7058\n",
      "Epoch 13/25\n",
      " - 104s - loss: 0.7058 - acc: 0.7536 - val_loss: 0.7426 - val_acc: 0.7508\n",
      "Epoch 14/25\n",
      " - 104s - loss: 0.6888 - acc: 0.7597 - val_loss: 0.6904 - val_acc: 0.7648\n",
      "Epoch 15/25\n",
      " - 104s - loss: 0.6849 - acc: 0.7633 - val_loss: 0.6829 - val_acc: 0.7648\n",
      "Epoch 16/25\n",
      " - 104s - loss: 0.6791 - acc: 0.7631 - val_loss: 0.7027 - val_acc: 0.7558\n",
      "Epoch 17/25\n",
      " - 104s - loss: 0.6525 - acc: 0.7734 - val_loss: 0.6842 - val_acc: 0.7694\n",
      "Epoch 18/25\n",
      " - 104s - loss: 0.6524 - acc: 0.7737 - val_loss: 0.7123 - val_acc: 0.7594\n",
      "Epoch 19/25\n",
      " - 104s - loss: 0.6493 - acc: 0.7720 - val_loss: 0.6893 - val_acc: 0.7638\n",
      "Epoch 20/25\n",
      " - 104s - loss: 0.6352 - acc: 0.7788 - val_loss: 0.6724 - val_acc: 0.7722\n",
      "Epoch 21/25\n",
      " - 104s - loss: 0.6307 - acc: 0.7814 - val_loss: 0.6896 - val_acc: 0.7656\n",
      "Epoch 22/25\n",
      " - 104s - loss: 0.6167 - acc: 0.7869 - val_loss: 0.7002 - val_acc: 0.7598\n",
      "Epoch 23/25\n",
      " - 104s - loss: 0.6275 - acc: 0.7845 - val_loss: 0.7214 - val_acc: 0.7576\n",
      "Epoch 24/25\n",
      " - 104s - loss: 0.6077 - acc: 0.7915 - val_loss: 0.7025 - val_acc: 0.7690\n",
      "Epoch 25/25\n",
      " - 104s - loss: 0.6119 - acc: 0.7892 - val_loss: 0.6960 - val_acc: 0.7718\n",
      "Точность работы на тестовых данных: 75.28%\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "numpy.random.seed(42)\n",
    "#Загрузить данные\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#нормализовать данные об интенсивности пикселей картинки\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "#преобразовать метки класса в категории\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "#создать модель\n",
    "model=Sequential()\n",
    "# Обязательно в слоях обработки изображения указывайте параметр data_format=\"channels_last\" или data_format=\"channels_first\", чтобы согласовать между слоями \n",
    "#положение переменной количества каналов, т.к. MaxPooling2D может урезать вам не само изображение а количество каналов, что вызовет ошибку\n",
    "\n",
    "model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='valid', input_shape=(32,32,3), activation='relu',data_format=\"channels_last\")) # (2)\n",
    "model.add(Convolution2D(filters=32, kernel_size=(3, 3), activation='relu',data_format=\"channels_last\")) # (3)\n",
    "model.add(MaxPooling2D(pool_size=(2,2), data_format='channels_last')) # (4)\n",
    "# Слой регуляризации \n",
    "model.add(Dropout(0.25)) \n",
    "\n",
    "# третий сверточный слой\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "# четвертый сверточный слой\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "# Второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Слой регуляризации \n",
    "model.add(Dropout(0.25))\n",
    "# Преобразование из двумерного вида в плоский\n",
    "model.add(Flatten())\n",
    "# Полносвязный слой\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# Слой регуляризации\n",
    "model.add(Dropout(0.5))\n",
    "# Выходной слой\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Описать сведение об архитектуре сети\n",
    "model_json = model.to_json()\n",
    "# Записать модель в файл\n",
    "json_file = open(\"neural_test.json\", \"w\")\n",
    "json_file.write(model_json)\n",
    "json_file.close()\n",
    "\n",
    "# Задаем параметры оптимизации\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "# Обучаем модель\n",
    "model.fit(X_train, Y_train,\n",
    "              batch_size=32,\n",
    "              nb_epoch=25,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True,\n",
    "              verbose=2)\n",
    "\n",
    "# Оцениваем качество обучения модели на тестовых данных\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "# Сохранить веса\n",
    "model.save_weights(\"neural_test.h5\")\n",
    "\n",
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
